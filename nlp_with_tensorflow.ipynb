{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinuka-kasun-medis/mycolab/blob/main/nlp_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MFt16hGWCntt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "nltk.download('words')\n",
        "english_words = words.words()\n",
        "\n",
        "def generate_misspelled_words(words_list, num_misspelled=1):\n",
        "    misspelled_words = []\n",
        "    for word in words_list:\n",
        "        for _ in range(num_misspelled):\n",
        "            random_index = np.random.randint(len(word))\n",
        "            misspelled_word = word[:random_index] + word[random_index + 1:]\n",
        "            misspelled_words.append((misspelled_word, word))\n",
        "    return misspelled_words\n",
        "\n",
        "misspelled_data = generate_misspelled_words(english_words, num_misspelled=1)\n",
        "misspelled_words, correct_words = zip(*misspelled_data)\n",
        "\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(correct_words)\n",
        "\n",
        "misspelled_sequences = tokenizer.texts_to_sequences(misspelled_words)\n",
        "correct_sequences = tokenizer.texts_to_sequences(correct_words)\n",
        "\n",
        "max_seq_length = max(max(len(seq) for seq in misspelled_sequences),\n",
        "                    max(len(seq) for seq in correct_sequences))\n",
        "\n",
        "misspelled_sequences = pad_sequences(misspelled_sequences, maxlen=max_seq_length, padding='post')\n",
        "correct_sequences = pad_sequences(correct_sequences, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n"
      ],
      "metadata": {
        "id": "T6E2uzkRXO2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify data shapes and types\n",
        "print(\"Shape of misspelled_sequences:\", misspelled_sequences.shape)\n",
        "print(\"Shape of correct_sequences:\", correct_sequences.shape)\n",
        "print(\"Data type of correct_sequences:\", correct_sequences.dtype)"
      ],
      "metadata": {
        "id": "QJsJWFonXU3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Embedding(vocab_size, 16, input_length=max_seq_length),\n",
        "#     tf.keras.layers.LSTM(64),\n",
        "#     tf.keras.layers.Dense(vocab_size, activation='softmax')  # Output units equal to vocab_size\n",
        "# ])\n",
        "\n",
        "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 16, input_length=max_seq_length),\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),  # Set return_sequences=True for TimeDistributed\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size, activation='softmax'))\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uwEfAKNeXfZH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the target labels to integer type (required for sparse_categorical_crossentropy)\n",
        "correct_sequences = correct_sequences.astype(np.int32)\n"
      ],
      "metadata": {
        "id": "Vest1HLYXil1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "model.fit(misspelled_sequences, correct_sequences, epochs=10, batch_size=32, validation_split=0.2) #me line eka."
      ],
      "metadata": {
        "id": "r1EQfcW8YL8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocess_word(word, tokenizer, max_seq_length):\n",
        "#     # Tokenize the input word into character-level sequence\n",
        "#     word_sequence = tokenizer.texts_to_sequences([word])\n",
        "#     # Pad the sequence to match the model's input length\n",
        "#     padded_sequence = pad_sequences(word_sequence, maxlen=max_seq_length, padding='post')\n",
        "#     return padded_sequence\n",
        "\n",
        "# def sequences_to_text(sequence, tokenizer):\n",
        "#     # Convert the sequence back to the word\n",
        "#     word = tokenizer.sequences_to_texts([sequence])[0]\n",
        "#     return word\n",
        "\n",
        "# def spell_check(word, tokenizer, max_seq_length):\n",
        "#     # Preprocess the input word\n",
        "#     input_sequence = preprocess_word(word, tokenizer, max_seq_length)\n",
        "#     # Predict the corrected word using the model\n",
        "#     predicted_sequence = model.predict(input_sequence)\n",
        "#     # Convert the sequence back to the word\n",
        "#     corrected_word = sequences_to_text(predicted_sequence[0], tokenizer)\n",
        "#     return corrected_word\n",
        "\n",
        "# # Example usage\n",
        "# input_word = \"bannna\"\n",
        "# corrected_word = spell_check(input_word, tokenizer, max_seq_length)\n",
        "# print(f\"Original word: {input_word}\")\n",
        "# print(f\"Corrected word: {corrected_word}\")\n"
      ],
      "metadata": {
        "id": "HnorCbsUeKqO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}